#!/bin/bash
set -e

export PROJECT="mozaggregator2bq"
export DATASET="aggregates"
export DATA_DIR="data"


function run_day {
    local aggregate_type=$1
    local ds_nodash=$2
    
    local input="$DATA_DIR/$aggregate_type/$ds_nodash"
    local intermediate="$DATA_DIR/parquet/$aggregate_type/$ds_nodash"
    local output=gs://$PROJECT/$DATA_DIR/$aggregate_type/$ds_nodash
    
    # chexk if this has already been done
    if ! gsutil stat "$output/_SUCCESS"; then
        # dump the table
        AGGREGATE_TYPE=$aggregate_type \
        DS_NODASH=$ds_nodash \
            scripts/pg_dump_by_day

        # create parquet
        echo "running for $intermediate"
        bin/submit-local scripts/pg_dump_to_parquet.py \
            --input-dir "$input" \
            --output-dir "$intermediate"
        
        gsutil rsync -d -r "$intermediate/" "$output/"
    fi
    bq load \
        --source_format=PARQUET \
        --autodetect \
        --replace \
        --time_partitioning_type DAY \
        --clustering_fields metric,version,channel,os \
        "$PROJECT:$DATASET.${aggregate_type}_aggregates\$${ds_nodash}" \
        "$output/*.parquet"
}


function ds_nodash_range {
    DS_START=$1 DS_END=$2 python3 - <<EOD
from datetime import date, timedelta, datetime
from os import environ

def parse(ds):
    return datetime.strptime(ds, "%Y-%m-%d")

start_date = parse(environ["DS_START"])
end_date = parse(environ["DS_END"])

dates = []
for i in range((end_date - start_date).days):
    dt = start_date + timedelta(i)
    dates.append(dt.strftime("%Y%m%d"))
print("\n".join(dates))
EOD
}


cd "$(dirname "$0")/.."

# checking if spark is enabled
python -c "import pyspark; print(pyspark.__path__[0])"

# checking if credentials are set, check export_credentials_s3 for full list
: "${POSTGRES_USER?}"

original_project=$(gcloud config get-value project)
function cleanup {
    gcloud config set project "$original_project"
}
trap cleanup EXIT
gcloud config set project $PROJECT

if ! bq ls $PROJECT:$DATASET; then
    bq mk $PROJECT:$DATASET
fi


mkdir -p "$DATA_DIR"
start_ds="2020-01-01"
end_ds="2020-01-02"
for ds_nodash in $(ds_nodash_range "$start_ds" "$end_ds"); do
    time run_day "submission_date" "$ds_nodash"
    time run_day "build_id" "$ds_nodash"
done
